[2016-02-17 22:24:49,019] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = false
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.9.0.X
	log.retention.hours = 168
	num.partitions = 1
	listeners = PLAINTEXT://:9092
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 524288000
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 30000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	unclean.leader.election.enable = true
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-02-17 22:24:49,378] WARN Please note that the support metrics collection feature ("Metrics") of Proactive Support is enabled.  With Metrics enabled, this broker is configured to collect and report certain broker and cluster metadata ("Metadata") about your use of the Confluent Platform 2.0 (including without limitation, your remote internet protocol address) to Confluent, Inc. ("Confluent") or its parent, subsidiaries, affiliates or service providers every 24hours.  This Metadata may be transferred to any country in which Confluent maintains facilities.  For a more in depth discussion of how Confluent processes such information, please read our Privacy Policy located at http://www.confluent.io/privacy. By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer, storage and use of Metadata by Confluent.  You can turn the Metrics feature off by setting `confluent.support.metrics.enable=false` in the broker configuration and restarting the broker.  See the Confluent Platform documentation for further information. (io.confluent.support.metrics.SupportedServerStartable)
[2016-02-17 22:24:49,387] INFO starting (kafka.server.KafkaServer)
[2016-02-17 22:24:49,395] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-02-17 22:24:49,417] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2016-02-17 22:24:49,429] INFO Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,429] INFO Client environment:host.name=wlezzar-HP-Pavilion-dv6-Notebook-PC (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,429] INFO Client environment:java.version=1.8.0_66-internal (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,429] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,429] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-i386/jre (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,429] INFO Client environment:java.class.path=:/opt/modules/confluent/current/bin/../libs/*:/opt/modules/confluent/current/bin/../share/java/kafka/kafka-tools-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/support-metrics-common-2.0.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-autoscaling-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-logging-1.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/joda-time-2.9.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-elasticloadbalancing-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-annotations-2.3.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jopt-simple-3.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-lang3-3.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jetty-servlet-9.2.12.v20150709.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cognitoidentity-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cloudformation-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/support-metrics-client-2.0.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cloudwatch-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cognitosync-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jersey-common-2.22.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-support-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/snappy-java-1.1.1.7.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka.jar:/opt/modules/confluent/current/bin/../share/java/kafka/connect-api-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka_2.11-0.9.0.0-cp1-scaladoc.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cloudtrail-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-digester-1.8.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/metrics-core-2.2.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-codec-1.9.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-glacier-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-s3-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-elastictranscoder-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka_2.11-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-simpleworkflow-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/opt/modules/confluent/current/bin/../share/java/kafka/log4j-1.2.17.jar:/opt/modules/confluent/current/bin/../share/java/kafka/lz4-1.2.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jetty-io-9.2.12.v20150709.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-datapipeline-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/httpclient-4.5.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/opt/modules/confluent/current/bin/../share/java/kafka/connect-json-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/hk2-utils-2.4.0-b31.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-route53-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cloudwatchmetrics-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-sqs-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-collections-3.2.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/hk2-locator-2.4.0-b31.jar:/opt/modules/confluent/current/bin/../share/java/kafka/support-metrics-fullcollector-2.0.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jetty-util-9.2.12.v20150709.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jersey-container-servlet-2.22.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/javassist-3.18.1-GA.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jersey-server-2.22.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/connect-runtime-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-core-2.5.4.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/opt/modules/confluent/current/bin/../share/java/kafka/httpcore-4.4.3.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-emr-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jersey-media-jaxb-2.22.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-opsworks-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-ec2-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/connect-file-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jetty-http-9.2.12.v20150709.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka-clients-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-importexport-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-logs-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-directconnect-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/paranamer-2.3.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-compress-1.9.jar:/opt/modules/confluent/current/bin/../share/java/kafka/javax.inject-2.4.0-b31.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cloudsearch-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jersey-container-servlet-core-2.22.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka_2.11-0.9.0.0-cp1-test.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-ses-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/slf4j-log4j12-1.7.6.jar:/opt/modules/confluent/current/bin/../share/java/kafka/scala-xml_2.11-1.0.4.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-dynamodb-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/commons-validator-1.4.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.5.4.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jersey-guava-2.22.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka-log4j-appender-0.9.0.0-cp1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/zookeeper-3.4.6.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka_2.11-0.9.0.0-cp1-sources.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-elasticbeanstalk-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/slf4j-api-1.7.6.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jersey-client-2.22.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jetty-server-9.2.12.v20150709.jar:/opt/modules/confluent/current/bin/../share/java/kafka/hk2-api-2.4.0-b31.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b31.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-core-2.3.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-storagegateway-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/javax.inject-1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/scala-library-2.11.7.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-elasticache-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-jaxrs-base-2.5.4.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-cloudfront-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/httpmime-4.5.1.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-redshift-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-kinesis-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/kafka_2.11-0.9.0.0-cp1-javadoc.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-sts-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-simpledb-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.5.4.jar:/opt/modules/confluent/current/bin/../share/java/kafka/avro-1.7.7.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-swf-libraries-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-databind-2.5.4.jar:/opt/modules/confluent/current/bin/../share/java/kafka/argparse4j-0.5.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/zkclient-0.7.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-core-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-annotations-2.5.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jackson-databind-2.3.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/jetty-security-9.2.12.v20150709.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-iam-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-rds-1.9.2.jar:/opt/modules/confluent/current/bin/../share/java/kafka/aws-java-sdk-sns-1.9.2.jar (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,429] INFO Client environment:java.library.path=/usr/java/packages/lib/i386:/usr/lib/i386-linux-gnu/jni:/lib/i386-linux-gnu:/usr/lib/i386-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,429] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,430] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,430] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,430] INFO Client environment:os.arch=i386 (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,430] INFO Client environment:os.version=4.2.0-22-generic (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,430] INFO Client environment:user.name=wlezzar (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,430] INFO Client environment:user.home=/home/wlezzar (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,430] INFO Client environment:user.dir=/home/wlezzar/MyFiles/projects/wiki_stream_catcher (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,431] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@e41621 (org.apache.zookeeper.ZooKeeper)
[2016-02-17 22:24:49,453] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2016-02-17 22:24:49,457] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2016-02-17 22:24:49,522] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2016-02-17 22:24:49,646] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x152f11efa070000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2016-02-17 22:24:49,650] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2016-02-17 22:24:50,016] INFO Log directory '/tmp/kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-02-17 22:24:50,036] INFO Loading logs. (kafka.log.LogManager)
[2016-02-17 22:24:50,045] INFO Logs loading complete. (kafka.log.LogManager)
[2016-02-17 22:24:50,059] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-02-17 22:24:50,061] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-02-17 22:24:50,064] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-02-17 22:24:50,175] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-02-17 22:24:50,180] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-02-17 22:24:50,294] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-02-17 22:24:50,295] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-02-17 22:24:50,478] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-02-17 22:24:50,522] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-02-17 22:24:50,537] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-02-17 22:24:50,728] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-02-17 22:24:50,730] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-02-17 22:24:50,731] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-02-17 22:24:50,732] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-02-17 22:24:50,888] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 160 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 22:24:50,894] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-02-17 22:24:50,895] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-02-17 22:24:50,917] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-02-17 22:24:50,931] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-02-17 22:24:51,008] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-02-17 22:24:51,032] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(wlezzar-HP-Pavilion-dv6-Notebook-PC,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-02-17 22:24:51,054] INFO Kafka version : 0.9.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)
[2016-02-17 22:24:51,054] INFO Kafka commitId : d1555e3a21980fa9 (org.apache.kafka.common.utils.AppInfoParser)
[2016-02-17 22:24:51,055] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-02-17 22:24:51,060] INFO Waiting 10039 ms for the monitored broker to finish starting up... (io.confluent.support.metrics.MetricsReporter)
[2016-02-17 22:24:51,074] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-02-17 22:25:01,103] INFO Monitored broker is now ready (io.confluent.support.metrics.MetricsReporter)
[2016-02-17 22:25:01,103] INFO Starting metrics collection from monitored broker... (io.confluent.support.metrics.MetricsReporter)
[2016-02-17 22:25:02,432] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-02-17 22:25:02,567] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-02-17 22:25:02,573] INFO Created log for partition [_schemas,0] in /tmp/kafka-logs with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-02-17 22:25:02,574] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-02-17 22:25:33,827] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [WikiStreamEvents,0],[WikiStreamEvents,1],[WikiStreamEvents,3],[WikiStreamEvents,4],[WikiStreamEvents,2] (kafka.server.ReplicaFetcherManager)
[2016-02-17 22:25:33,834] INFO Completed load of log WikiStreamEvents-2 with log end offset 0 (kafka.log.Log)
[2016-02-17 22:25:33,836] INFO Created log for partition [WikiStreamEvents,2] in /tmp/kafka-logs with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 3600000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-02-17 22:25:33,836] INFO Partition [WikiStreamEvents,2] on broker 0: No checkpointed highwatermark is found for partition [WikiStreamEvents,2] (kafka.cluster.Partition)
[2016-02-17 22:25:33,840] INFO Completed load of log WikiStreamEvents-3 with log end offset 0 (kafka.log.Log)
[2016-02-17 22:25:33,842] INFO Created log for partition [WikiStreamEvents,3] in /tmp/kafka-logs with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 3600000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-02-17 22:25:33,842] INFO Partition [WikiStreamEvents,3] on broker 0: No checkpointed highwatermark is found for partition [WikiStreamEvents,3] (kafka.cluster.Partition)
[2016-02-17 22:25:33,845] INFO Completed load of log WikiStreamEvents-0 with log end offset 0 (kafka.log.Log)
[2016-02-17 22:25:33,846] INFO Created log for partition [WikiStreamEvents,0] in /tmp/kafka-logs with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 3600000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-02-17 22:25:33,847] INFO Partition [WikiStreamEvents,0] on broker 0: No checkpointed highwatermark is found for partition [WikiStreamEvents,0] (kafka.cluster.Partition)
[2016-02-17 22:25:33,850] INFO Completed load of log WikiStreamEvents-4 with log end offset 0 (kafka.log.Log)
[2016-02-17 22:25:33,852] INFO Created log for partition [WikiStreamEvents,4] in /tmp/kafka-logs with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 3600000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-02-17 22:25:33,852] INFO Partition [WikiStreamEvents,4] on broker 0: No checkpointed highwatermark is found for partition [WikiStreamEvents,4] (kafka.cluster.Partition)
[2016-02-17 22:25:33,867] INFO Completed load of log WikiStreamEvents-1 with log end offset 0 (kafka.log.Log)
[2016-02-17 22:25:33,868] INFO Created log for partition [WikiStreamEvents,1] in /tmp/kafka-logs with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 3600000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-02-17 22:25:33,868] INFO Partition [WikiStreamEvents,1] on broker 0: No checkpointed highwatermark is found for partition [WikiStreamEvents,1] (kafka.cluster.Partition)
[2016-02-17 22:34:50,727] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 22:44:50,726] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 22:54:50,726] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 23:04:50,727] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 23:14:50,727] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 23:24:50,727] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 23:34:50,726] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 23:44:50,726] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-17 23:45:20,072] INFO Rolled new log segment for 'WikiStreamEvents-2' in 11 ms. (kafka.log.Log)
[2016-02-17 23:45:20,074] INFO Scheduling log segment 0 for log WikiStreamEvents-2 for deletion. (kafka.log.Log)
[2016-02-17 23:45:20,077] INFO Rolled new log segment for 'WikiStreamEvents-0' in 2 ms. (kafka.log.Log)
[2016-02-17 23:45:20,077] INFO Scheduling log segment 0 for log WikiStreamEvents-0 for deletion. (kafka.log.Log)
[2016-02-17 23:45:20,079] INFO Rolled new log segment for 'WikiStreamEvents-4' in 1 ms. (kafka.log.Log)
[2016-02-17 23:45:20,079] INFO Scheduling log segment 0 for log WikiStreamEvents-4 for deletion. (kafka.log.Log)
[2016-02-17 23:45:20,081] INFO Rolled new log segment for 'WikiStreamEvents-1' in 1 ms. (kafka.log.Log)
[2016-02-17 23:45:20,081] INFO Scheduling log segment 0 for log WikiStreamEvents-1 for deletion. (kafka.log.Log)
[2016-02-17 23:45:20,085] INFO Rolled new log segment for 'WikiStreamEvents-3' in 3 ms. (kafka.log.Log)
[2016-02-17 23:45:20,085] INFO Scheduling log segment 0 for log WikiStreamEvents-3 for deletion. (kafka.log.Log)
[2016-02-17 23:46:20,076] INFO Deleting segment 0 from log WikiStreamEvents-2. (kafka.log.Log)
[2016-02-17 23:46:20,078] INFO Deleting segment 0 from log WikiStreamEvents-0. (kafka.log.Log)
[2016-02-17 23:46:20,080] INFO Deleting index /tmp/kafka-logs/WikiStreamEvents-0/00000000000000000000.index.deleted (kafka.log.OffsetIndex)
[2016-02-17 23:46:20,080] INFO Deleting index /tmp/kafka-logs/WikiStreamEvents-2/00000000000000000000.index.deleted (kafka.log.OffsetIndex)
[2016-02-17 23:46:20,080] INFO Deleting segment 0 from log WikiStreamEvents-4. (kafka.log.Log)
[2016-02-17 23:46:20,081] INFO Deleting index /tmp/kafka-logs/WikiStreamEvents-4/00000000000000000000.index.deleted (kafka.log.OffsetIndex)
[2016-02-17 23:46:20,082] INFO Deleting segment 0 from log WikiStreamEvents-1. (kafka.log.Log)
[2016-02-17 23:46:20,082] INFO Deleting index /tmp/kafka-logs/WikiStreamEvents-1/00000000000000000000.index.deleted (kafka.log.OffsetIndex)
[2016-02-17 23:46:20,086] INFO Deleting segment 0 from log WikiStreamEvents-3. (kafka.log.Log)
[2016-02-17 23:46:20,086] INFO Deleting index /tmp/kafka-logs/WikiStreamEvents-3/00000000000000000000.index.deleted (kafka.log.OffsetIndex)
[2016-02-17 23:54:50,726] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
